{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYwLs5joJfJN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMAvgHx6JfJm"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfgmDl7JJfJn"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQFbVbtpJfJn"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "* In this homework you are going to apply supervised learning: Linear Regression method using Scikit-learn package; Scikit-learn (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy [https://en.wikipedia.org/wiki/Scikit-learn].\n",
    "\n",
    "### The homework is divided into four sections and the points are distributed as below:\n",
    "<pre>\n",
    "- Linear Regression    -> 2 points\n",
    "- PCA                  -> 2 points\n",
    "- Overfitting          -> 5 points\n",
    "_________________________________________\n",
    "Total                  -> 9 points\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1wszlIpJfJo"
   },
   "source": [
    "# 1. Regression \n",
    "## 1.1 Linear Regression (2 points)\n",
    "\n",
    "We are going to use the Prices dataset that contains 74 columns. Each column represents a feature of houses for sale. The ```SalePrice``` column  shows their prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qidamLnMJfJo",
    "outputId": "e18bb5ca-1505-4ef4-e49f-e2cde4d0db2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
       "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
       "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
       "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
       "       'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt', 'GarageFinish',\n",
       "       'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
       "       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Prices.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5dxc_JaJfJq"
   },
   "source": [
    "The column names are self-explanatory which indicates features of each house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt1Kln3rJfJq"
   },
   "source": [
    "**1.1.1. The target label is```SalePrice``` which means, later we will predict the sale-price based on the given features (columns). But for regression task, it is important to ensure that the data is not skewed. In order to do that, please plot the distribution of ```SalePrice``` column and explain what do you see. (0.2 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "IJbRJKE8JfJq",
    "outputId": "09065320-3c54-4d4c-e2c8-ca7b6d3c19b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f963119bfd0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data.hist(\"SalePrice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UthxdZLyJfJq"
   },
   "source": [
    "**<font color='red'>Answer:</font>** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCEjKtlJJfJr"
   },
   "source": [
    "So, the data seems to be skewed which has to be fixed otherwise it may lead to erronous result. \n",
    "Apart from that, look closely, some columns are not numerical. For those, you have to convert them to numerical value or represent them in a way so that the algorithm can understand the data. One of such way is called, one hot encoding. Along with that, the algorithm cannot deal with NaN or Infinite values. So please address all of these in the preprocessing section. \n",
    "\n",
    "- Preprocess for skewed data\n",
    "- Apply one-hot encoding to categorical data types\n",
    "- Replace negative infinite values with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1s3u1LLJfJr"
   },
   "source": [
    "**1.1.2. After preprocessing the skewed data, plot ```SalePrice``` column distribution again. (0.05 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "hl0qQwwdJfJs",
    "outputId": "7af43982-fc2e-4fcb-d852-8b0ee61246d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.880940746034036\n",
      "0.1212103673013655\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d9335cfb-f598-42a3-8621-21df29b67487\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>460</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>836</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>500</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>240</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>276</td>\n",
       "      <td>736</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 10 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9335cfb-f598-42a3-8621-21df29b67487')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d9335cfb-f598-42a3-8621-21df29b67487 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d9335cfb-f598-42a3-8621-21df29b67487');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      GarageArea  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0            548           0           61              0          0   \n",
       "1            460         298            0              0          0   \n",
       "2            608           0           42              0          0   \n",
       "3            642           0           35            272          0   \n",
       "4            836         192           84              0          0   \n",
       "...          ...         ...          ...            ...        ...   \n",
       "1455         460           0           40              0          0   \n",
       "1456         500         349            0              0          0   \n",
       "1457         252           0           60              0          0   \n",
       "1458         240         366            0            112          0   \n",
       "1459         276         736           68              0          0   \n",
       "\n",
       "      ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \n",
       "0               0         0        0       2    2008  \n",
       "1               0         0        0       5    2007  \n",
       "2               0         0        0       9    2008  \n",
       "3               0         0        0       2    2006  \n",
       "4               0         0        0      12    2008  \n",
       "...           ...       ...      ...     ...     ...  \n",
       "1455            0         0        0       8    2007  \n",
       "1456            0         0        0       2    2010  \n",
       "1457            0         0     2500       5    2010  \n",
       "1458            0         0        0       4    2010  \n",
       "1459            0         0        0       6    2008  \n",
       "\n",
       "[1460 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "new_data=data.copy()\n",
    "\n",
    "print(skew(new_data['SalePrice']))\n",
    "new_data['SalePrice']=np.log(new_data['SalePrice'])\n",
    "print(skew(new_data['SalePrice']))\n",
    "\n",
    "\n",
    "\n",
    "new_data['SalePrice'].hist()\n",
    "\n",
    "\n",
    "bool_columns = new_data.applymap(np.isreal).all()\n",
    "\n",
    "# df.info()\n",
    "columns=new_data.columns\n",
    "\n",
    "\n",
    "# find categorical columns\n",
    "categorical_columns=[]\n",
    "numerical_colunms=[]\n",
    "for i in range(len(columns)):\n",
    "    if bool_columns[i]==False:\n",
    "        categorical_columns.append(columns[i])\n",
    "    if bool_columns[i]==True:\n",
    "        numerical_colunms.append(columns[i])\n",
    "        \n",
    "        \n",
    "numerical_data= new_data[numerical_colunms]       \n",
    "df=pd.get_dummies(new_data[categorical_columns])\n",
    "finaly_numerical_datd=pd.concat([df,numerical_data],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "finaly_numerical_datd[\"SalePrice\"].values\n",
    "finaly_numerical_datd.columns\n",
    "finaly_numerical_datd.iloc[:,260:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQPBZ0QWJfJs"
   },
   "source": [
    "**1.1.3. Calculate the correlation between price and each feature. Which are the top 3 features that have the highest correlation with  price? Is the correlation positive or negative? Explain what happens with the price when each of those 3 features change (consider only one feature at a time) and others are kept constant. (0.25 point)** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A59X1K5fJfJs"
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMeYdpcJWD6n"
   },
   "source": [
    "### OverallQual    and GrLivArea      and GarageCars     have the hieghest coorelation And theyre value is positive  so both variables change in the same direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLYyFSd-JfJt"
   },
   "source": [
    "<font color='red'> **Answer:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qQzbp4RJfJt"
   },
   "source": [
    "**1.1.4.  Now you have to build a regression model that would be trained on training data and later predict the price on test data. You are free to select features on which you want train the model. The dataset has missing values, so please apply the following methods to deal with the missing data in the features of your choice:**\n",
    "\n",
    "a) mean imputation\n",
    "\n",
    "b) median imputation\n",
    "\n",
    "c) mode imputation\n",
    "\n",
    "d) dropping missing values\n",
    "\n",
    "**Split dataset into the training (80% of the all rows) and test ( 20% of all rows) set, you can use train_test_split function from scikit-learn. While splitting, set the parameter random_state equal to 2, this will reproduce similar split during grading.**\n",
    "\n",
    "**For each of the case report MAE, RMSE and R<sup>2</sup>. Which method works better ?(1.50 points)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fq5ab-_bWD6o",
    "outputId": "f2a8b8fe-cdad-4d62-dc0f-de13f6fd4b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: mean imputation  MAE: 333.57941436553114  RMSE: 8101701.060500617  R2: -48143529.72043482\n",
      "Method: median imputation  MAE: 26.469332990377644  RMSE: 65414.43290452872  R2: -388717.58349021856\n",
      "Method: mode imputation  MAE: 0.0872152700088956  RMSE: 0.024563542201419892  R2: 0.8540336603701244\n",
      "Method: dropping missing values  MAE: 559.334114494046  RMSE: 17693672.677497484  R2: -120797501.89980614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "methods = ['mean imputation', 'median imputation', 'mode imputation', 'dropping missing values']\n",
    "#Store the result in the following variables\n",
    "MAE = []\n",
    "RMSE = []\n",
    "R2 = []\n",
    "#TODO\n",
    "\n",
    "\n",
    "#print the metrics\n",
    "i = 0\n",
    "\n",
    "for m in methods:\n",
    "    dataset=finaly_numerical_datd.copy()\n",
    "    if m ==\"dropping missing values\" :\n",
    "        \n",
    "        dataset.dropna(axis=0,inplace=True,how=\"any\")\n",
    "    elif m==\"mode imputation\" :  \n",
    "        dataset.fillna(df.mode(),inplace=True)\n",
    "        dataset=dataset.replace(np.nan,0)\n",
    "    else:\n",
    "        strategy=m.split(\" \")[0]\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy=strategy)\n",
    "        dataset=imp.fit_transform(dataset)\n",
    "        \n",
    "        \n",
    "    \n",
    "       \n",
    "    dataset=pd.DataFrame(dataset)    \n",
    "    x=dataset.iloc[:,:-1].values\n",
    "    y=dataset.iloc[:,-1].values\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=2)\n",
    "    model=LinearRegression().fit(xtrain,ytrain) \n",
    "   \n",
    "    yhat=model.predict(xtest)\n",
    "    \n",
    "    \n",
    "    MAE.append(mean_absolute_error(ytest,yhat))\n",
    "    RMSE.append(mean_squared_error(ytest,yhat))\n",
    "    R2.append(r2_score(ytest,yhat))\n",
    "    print(\"Method: \" + m + \"  MAE: \" + str(MAE[i]) + \"  RMSE: \" + str(RMSE[i]) + \"  R2: \" + str(R2[i]))\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FebwtCaGWD6p",
    "outputId": "43b798d0-6db2-4fe1-ac8f-a67b3067115a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.79433792 11.6784399  11.74799759 11.85082525 12.25486281 12.73596533\n",
      " 11.78600139 11.92503512 11.7905572  12.23563145 12.93675161 12.90420737\n",
      " 12.31716669 11.87756858 12.87901712 12.07823927 11.79810441 11.81303006\n",
      " 12.01364014 11.9511804 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11.83, 11.65, 11.73, 11.78, 12.23, 12.74, 11.8 , 11.96, 11.62,\n",
       "       12.18, 12.88, 12.98, 12.28, 11.92, 12.52, 12.  , 11.73, 11.75,\n",
       "       12.15, 12.  ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ytest[0:20])\n",
    "yhat[0:20].round(2)\n",
    "# r2_score(ytest[0:75],yhat[0:75].round(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "di6eU4kRJfJt"
   },
   "source": [
    "<font color='red'> **Answer:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4mCTiasJfJu"
   },
   "source": [
    "**Please store the best MAE, RMSE, r2_best score in the following variables. We will use these variable to compare ```1.2.7```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XD8eDSFNJfJv"
   },
   "outputs": [],
   "source": [
    "mae_best =  0.09805344882247011  #best MAE\n",
    "rmse_best =0.021131692697953477 #best RMSE\n",
    "r2_best =  0.8744270753781864   #best R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgkUo5YBJfJv"
   },
   "source": [
    "# 1.2 Principal Component Analysis (PCA) (2 points)\n",
    "Our model performs quite good. But there is always room to make it better and simpler. By simpler, we mean the reducing the dimensionality of the dataset so that we can have a simpler linear regression model. <br> <br>If you noticed after one-hot encoding, we have 270 features (columns) but all these features do not hold the same level of information. For example, the first feature may hold 50% of the information required to make the linear regression acheive the performance we already had; the last, (feature number 270) may contribute to only 0.0000001% to the total output. Hence, adding this last variable (actually there could be more) to our linear regression model (read equation) will only increase the complexity of the model; space, time and computational complexity. Therefore, it is wise and desirable to make the model simpler yet performing the best (better). \n",
    "<br> <br>\n",
    "One such way to reduce the dimensionality of the dataset is known as Pricipal Component Analysis. Using this method, we can find out which features contribute the most in our model, therefore, we can wisely select how many we need. We will perform, PCA in this section of the homework. <br><br>\n",
    "\n",
    "*There is another powerful method for dimensionality reduction, named t-SNE. We will use t-sne in future homework. <br><br>*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gm5DmYT3JfJv"
   },
   "source": [
    "**1.2.1. From ```1.1.4``` keep the best method to deal with missing values and apply PCA to reduce the number of features. (0.5point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zy7hzDhHJfJv",
    "outputId": "7eeebf82-322b-4837-99ce-b79598cb7b97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "dataset=finaly_numerical_datd.copy() \n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "dataset=pd.DataFrame(dataset)  \n",
    "dataset=imp.fit_transform(dataset)\n",
    "dataset=pd.DataFrame(dataset) \n",
    "x=dataset.iloc[:,200:-1].values\n",
    "y=dataset.iloc[:,-10].values\n",
    "pca=PCA(n_components=10).fit(x)\n",
    "x=pca.transform(x)\n",
    "# xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=5)\n",
    "# model=LinearRegression().fit(xtrain,ytrain)         \n",
    "\n",
    "\n",
    "#TODO: initialize pca, pass, whiten=True, svd_solver='randomized', random_state=0\n",
    "\n",
    "\n",
    "#TODO: fit pc\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-w3klggJfJw"
   },
   "source": [
    "**1.2.2. What percentage of the variance is explained by the first five components? (0.10 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVlbjHOxWD6u",
    "outputId": "e6bc0ec0-2feb-4771-e843-2462aac3966e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983242895789477"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQEVP0WjJfJw"
   },
   "source": [
    "<font color='red'> **Answer:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7ELb09LJfJw"
   },
   "source": [
    "It would be helpful if we could see all of the variance against the number of components, so a plot would give us a better understanding of the situation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3FzebW5JfJ2"
   },
   "source": [
    "**1.2.3. Please plot the result of PCA you built in ```1.2.1```<br>\n",
    "X-axis=Number of Components, Y-axis=Total explained variance and explain the result.(0.5 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "Irp6UKBbJfJ3",
    "outputId": "2c4ec833-79c1-4f27-e409-a1e4ea948c5e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Number_of_Components=[i for i in range(1,11)]\n",
    "explained_variance=pca.explained_variance_\n",
    "plt.figure(figsize=(10,7))\n",
    "lw=2\n",
    "plt.plot(Number_of_Components,explained_variance, color='k', lw=lw)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Total explained variance')\n",
    "    \n",
    "plt.xlim(0, 30)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plt.axhline(0.9, c='c')\n",
    "plt.show()\n",
    "Number_of_Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHnlCo-5JfJ3"
   },
   "source": [
    "<font color='red'> **Answer:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_4PB8XRJfJ4"
   },
   "source": [
    "**1.2.5. Again, from ```1.1.4``` keep the best method to deal with missing values and use PCA to reduce the number of features. But you can use only the number of features that are significant in ```1.1.3```, in this case you have to choose an optimum n_component value based on the PCA plot. Otherwise, you can select all of the features and pass the n_components=37. In all cases, keep random_state for PCA equal to 0. (0.20 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "T5V5J9lkJfJ4",
    "outputId": "3699c7e0-8cdb-4589-f1ad-46a1cafd9066"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "dataset=finaly_numerical_datd.copy() \n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "dataset=pd.DataFrame(dataset)  \n",
    "dataset=imp.fit_transform(dataset)\n",
    "dataset=pd.DataFrame(dataset) \n",
    "x=dataset.iloc[:,200:-1].values\n",
    "y=dataset.iloc[:,-10].values\n",
    "pca=PCA(n_components=3).fit(x)\n",
    "x=pca.transform(x)\n",
    "\n",
    "\n",
    "Number_of_Components=[i for i in range(1,4)]\n",
    "explained_variance=pca.explained_variance_\n",
    "plt.figure(figsize=(10,7))\n",
    "lw=2\n",
    "plt.plot(Number_of_Components,explained_variance, color='k', lw=lw)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Total explained variance')\n",
    "    \n",
    "plt.xlim(0, 30)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plt.axhline(0.9, c='c')\n",
    "plt.show()\n",
    "Number_of_Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ii2fvRuJfJ4"
   },
   "source": [
    "**1.2.6. Use the new components derived from PCA to predict the house prices. Keep the ratio of test and train set to 20/80 and the random_state equal to 0. Report MAE, RMSE and R<sup>2</sup> (0.60 point)** <br>\n",
    "*Hint: Now your training data is different. Please use pca.transform(X) function to create your new training dataset. But make sure you have the fitted pca from ```1.2.5```*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "id": "nO8i5zgiJfJ4",
    "outputId": "04f97d7a-bda4-4f94-8160-985d54fa13b6"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-618c3d54819d>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    X_train_pca, X_test_pca, y_train_pca, y_test_pca = #TODO\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pca_X = pca.transform(X)\n",
    "\n",
    "\n",
    "methods = ['mean imputation', 'median imputation', 'mode imputation', 'dropping missing values']\n",
    "MAE = []\n",
    "RMSE = []\n",
    "R2 = []\n",
    "    \n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = #TODO\n",
    "\n",
    "regressor = LinearRegression()\n",
    "\n",
    "#TODO: train the regression model\n",
    "\n",
    "y_predicted_pca = #TODO: predict on test dataset\n",
    "\n",
    "mae_pca = #TODO: mean absolute error\n",
    "rmse_pca = #TODO: root mean squared error\n",
    "r2_pca = #TODO: R^2\n",
    "\n",
    "    \n",
    "print(\"MAE: \" + str(mae_pca) + \"  RMSE: \" + str(rmse_pca) + \"  R2: \" + str(r2_pca))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJ8DEaLyJfJ4"
   },
   "source": [
    "**1.2.7 The following cell would calculate the difference between pre-PCA and post-PCA. Please explain the situation based on the differences. (0.1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLFLGYHnJfJ5"
   },
   "outputs": [],
   "source": [
    "print(\"MAE difference after PCA: \", mae_best-mae_pca)\n",
    "print(\"RMSE difference after PCA: \", rmse_best-rmse_pca)\n",
    "print(\"R2 difference after PCA: \", r2_best-r2_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTZCW4GEJfJ5"
   },
   "source": [
    "<font color='red'> **Answer:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVj81M_uJfJ5"
   },
   "source": [
    "## 1.3 Overfitting (5 points)\n",
    "\n",
    "Now our model is comparatively better than the earlier models. It is less complex yet performs the almost the same. Let's dive a little deeper into the model now. In this section, we will check if the model is overfitting. The concept of overfitting has already been delivered in the lectures. However, if you are interesed in honing it up, please take a look here or anywhere you understand better: https://datascience.foundation/sciencewhitepaper/underfitting-and-overfitting-in-machine-learning\n",
    "<br>\n",
    "<br>\n",
    "Unfortunately it is difficult to know if a model is overfitting or underfitting. One way to know more about model's performance is cross-validation. Cross-validation is also used in the hyperparameter searching to find the best performing model in a given scenario.  \n",
    "We have a few techniques to prevent overfitting and we will focus on \n",
    "- 1.3.1 Cross-validation \n",
    "    - K-Fold cross-validation: Most common (we would apply this one to see the performance of the Linear regression model)\n",
    "    - Leave One Out (LOO): Takes each row as the validation set for once, and trains the model on the rest n-1 rows. Thus, it trains n number of models.\n",
    "\n",
    "    - Leave P-Out (LPO): Creates possible splits after leaving p samples out. For n rows, there would be (nCp) possibile train-test splits.\n",
    "    - (For classification problems) Stratified K-Fold: Ensures relative class proportion is preserved in each train and validation fold. Important when the class label is imbalanced (e.g. 95% label: 1; 5% label: 0).\n",
    "    \n",
    "    *The last three techniques will be discussed in detail in the Lecture 7.* <br><br>\n",
    "    \n",
    "- 1.3.2 Regularization \n",
    "    - L1 (Lasso)    \n",
    "    - L2 (Ridge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgnrzErbJfJ5"
   },
   "source": [
    "**1.3.0. Now we have to check if the trained regression model in ```1.1.4``` is overfitting. Please use R<sup>2</sup> value on train and test result to determine the overfitting. Please explain the result from the perspective of the dataset and the value(0.2 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-U9AhTxCJfJ5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aejhzWfUJfJ6"
   },
   "source": [
    "<font color='red'> **Answer:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "la1JX3IhJfJ6"
   },
   "source": [
    "**1.3.1 Please apply K-fold=10 fold cross validation on the training dataset of ```1.1.4``` Keep random_state=1, shuffle=True, while performing cross validation, make sure that return_train_score=True.(0.5 point)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cZsA7alJfJ6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "cv = KFold(#TODO: pass parameeter)\n",
    "#TODO: create model\n",
    "\n",
    "#TODO: evaluate model using R^2, and MSE as evaluation metrics\n",
    "#While setting MSE metrics, make sure you pass the right keyword \n",
    "\n",
    "\n",
    "# report performance\n",
    "print('R^2: %.3f (%.3f)' % (mean(scores['test_r2']), std(scores['test_r2'])))\n",
    "print('MSE: %.3f (%.3f)' % (mean(scores['test_neg_mean_squared_error']), std(scores['test_neg_mean_squared_error'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TALQSL6JJfJ6"
   },
   "source": [
    "**1.3.1.2. Please plot the training and test R<sup>2</sup> value where X-axis=number of folds, Y-axis=R<sup>2</sup> value. Explain the plot, if the model shows overfitting or not.(0.3 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6AxRDbsJfJ6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "#TODO: plot the trendlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qq62bO4LJfJ6"
   },
   "source": [
    "<font color='red'> **Answer:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRU2r7W0JfJ7"
   },
   "source": [
    "**1.3.2  Please apply L1 (Lasso) regularization with variable alpha parameters and report the corresponding alpha value and R<sup>2</sup> value. Use the training split from ```1.1.4``` (1.5 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBLdIUk6JfJ7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "\n",
    "cross_val_scores_lasso = [] \n",
    "  \n",
    "# List to maintain the different values of alpha \n",
    "alpha = [] \n",
    "\n",
    "\n",
    "\n",
    "# Loop to for different alpha value \n",
    "for i in range(1, 9): \n",
    "    #TODO: formulate the lasso model where alpha=i * 0.0001\n",
    "\n",
    "    #TODO: fit the lasso model on whole X, y\n",
    "    #TODO: perform 10 fold cross validation and store the result in score variable\n",
    "    scores = #TODO \n",
    "    avg_cross_val_score = mean(scores)*100\n",
    "    \n",
    "    cross_val_scores_lasso.append(avg_cross_val_score) \n",
    "    alpha.append(i * 0.0001) \n",
    "  \n",
    "# Loop to print the different values of cross-validation scores \n",
    "for i in range(0, len(alpha)): \n",
    "    print(str(alpha[i])+' : '+str(cross_val_scores_lasso[i])) \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bfFzmDfJfJ7"
   },
   "source": [
    "**1.3.3. Take the best alpha value from ```1.3.2``` and use it to train a new lasso model and report the  R<sup>2</sup> value on test set. Use the train test split from ```1.1.4```. (0.5 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26ebQVQ6JfJ7"
   },
   "outputs": [],
   "source": [
    "# Building and fitting the Lasso Regression Model \n",
    "from sklearn.model_selection import train_test_split\n",
    "lassoModelBest = Lasso(#TODO: pass the best alpha value) \n",
    "\n",
    "#TODO: Fit the model again \n",
    "  \n",
    "# Evaluating the Lasso Regression model \n",
    "print(lassoModelBest.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNhJ6cwkJfJ7"
   },
   "source": [
    "**1.3.4.  Please apply L2 (Ridge) regularization with variable alpha parameters and report the corresponding alpha value and R<sup>2</sup> value. Use the training split from ```1.1.4``` (1.5 point)**\n",
    "\n",
    "N.B. The $alpha$ here in the ridge regularization is the same as $lambda$ you saw in the lecture. We did not initiate the variable with $lambda$ because $lambda$ is a reserved keyword in python which is used to create small anonymous functions. A $lambda$ function can take any number of arguments, but can only have one expression.\n",
    "You can read more about it here: https://www.w3schools.com/python/ref_keyword_lambda.asp#:~:text=The%20lambda%20keyword%20is%20used,and%20the%20result%20is%20returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQXWz0z4JfJ8"
   },
   "outputs": [],
   "source": [
    "cross_val_scores_ridge = [] \n",
    "  \n",
    "# List to maintain the different values of alpha \n",
    "alpha = [] \n",
    "\n",
    "\n",
    "\n",
    "# Loop to for different alpha value \n",
    "for i in range(1, 9): \n",
    "    #TODO: formulate the ridge model where alpha=i * 0.0001\n",
    "\n",
    "    #TODO: fit the ridge model on whole X, y\n",
    "    #TODO: perform 10 fold cross validation and store the result in score variable\n",
    "    scores = #TODO \n",
    "    avg_cross_val_score = mean(scores)*100\n",
    "    \n",
    "    cross_val_scores_ridge.append(avg_cross_val_score) \n",
    "    alpha.append(i * 0.0001) \n",
    "  \n",
    "# Loop to print the different values of cross-validation scores \n",
    "for i in range(0, len(alpha)): \n",
    "    print(str(alpha[i])+' : '+str(cross_val_scores_ridge[i])) \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3k6yZXNJfJ8"
   },
   "source": [
    "**1.3.5. Take the best alpha value from ```1.3.4``` and use it to train a new ridge model and report the  R<sup>2</sup> value on test set. Use the train test split from ```1.1.4```. (0.5 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JB_FtNHeJfJ8"
   },
   "outputs": [],
   "source": [
    "# Building and fitting the Ridge Regression Model \n",
    "from sklearn.model_selection import train_test_split\n",
    "ridgeModelBest = Ridge(#TODO: pass the best alpha value) \n",
    "\n",
    "#TODO: Fit the model again \n",
    "  \n",
    "# Evaluating the ridge Regression model \n",
    "print(ridgeModelBest.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-5hoCclJfJ8"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
